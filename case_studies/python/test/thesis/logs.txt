/opt/anaconda3/envs/rsqtoa/bin/python /Users/ashish/work/thesis/rsqtoa/case_studies/python/test/10000/thesis/show_case_thesis.py
Total compile time :: 0.00946694800000003

New Subspace Node: lower=[0. 0.] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8027927650927165) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.22998803315005079) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.8880288705139954) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3336732143527721) > epsilon (0.001)

Subspace division depth: 1

Splitting dim 0 at 0.5

New Subspace Node: lower=[0. 0.] upper=[0.5 1. ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.16327160302600152) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.09765048099596885) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.171406366501207) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3212619045340519) > epsilon (0.001)

New Subspace Node: lower=[0.5 0. ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.19309919430754396) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.15393336483869557) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.116726366580344) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.4113393259098759) > epsilon (0.001)
Effectiveness: 1 1

Splitting dim 1 at 0.5

New Subspace Node: lower=[0. 0.] upper=[1.  0.5]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7328043692867507) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.31881734039678755) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.23875174961454482) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.1273302302350845) > epsilon (0.001)

New Subspace Node: lower=[0.  0.5] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7952855907539194) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.31574486148365555) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5979922647288918) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (9.681144774731365e-14) < epsilon (0.001)
Effectiveness: 1 2582339237

Right expansion step 1:

Splitting dim 1 at 0.25

New Subspace Node: lower=[0. 0.] upper=[1.   0.25]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.793937784673393) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4572452455659448) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (4.440892098500626e-16) < epsilon (0.001)

New Subspace Node: lower=[0.   0.25] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.9126245672275339) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.26051358393654134) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.390208477985981) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.016525522421998673) > epsilon (0.001)
Failure - keep old effectiveness: 2582339237

Right expansion step 2:

Splitting dim 1 at 0.375

New Subspace Node: lower=[0. 0.] upper=[1.    0.375]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.9046941471855661) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3677002334626267) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.040192556317848904) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.030938089042015893) > epsilon (0.001)

New Subspace Node: lower=[0.    0.375] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8553145102155915) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4033904401149222) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.9790185266232156) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (6.572520305780927e-14) < epsilon (0.001)
Success - new effectiveness: 4754644878

Right expansion step 3:

Splitting dim 1 at 0.3125

New Subspace Node: lower=[0. 0.] upper=[1.     0.3125]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.9180304517413165) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.40180084258714865) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (0.0004486556018168386) < epsilon (0.001)

New Subspace Node: lower=[0.     0.3125] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8982887564178696) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3218055167679301) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.9633199260561294) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (2.886579864025407e-14) < epsilon (0.001)
Success - new effectiveness: 11908556708

Right expansion step 4:

Splitting dim 1 at 0.28125

New Subspace Node: lower=[0. 0.] upper=[1.      0.28125]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7789468110428808) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3988341740357899) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (8.881784197001252e-16) < epsilon (0.001)

New Subspace Node: lower=[0.      0.28125] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8268321227742126) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3981315535152974) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2982904954891437) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.0027470426544238258) > epsilon (0.001)
Failure - keep old effectiveness: 11908556708

Right expansion step 5:

Splitting dim 1 at 0.296875

New Subspace Node: lower=[0. 0.] upper=[1.       0.296875]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7947871911996041) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4999745757050704) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (4.440892098500626e-16) < epsilon (0.001)

New Subspace Node: lower=[0.       0.296875] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8345030525447044) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.43958050795777615) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.1741349103000092) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (2.732272701422289e-07) < epsilon (0.001)
Success - new effectiveness: 1288

Right expansion step 6:

Splitting dim 1 at 0.2890625

New Subspace Node: lower=[0. 0.] upper=[1.        0.2890625]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8036467308002251) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.35336105282385755) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (4.440892098500626e-16) < epsilon (0.001)

New Subspace Node: lower=[0.        0.2890625] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8025769344028824) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.401308854810444) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2756724247476914) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.0006988630509385807) < epsilon (0.001)
Success - new effectiveness: 2

Right expansion step 7:

Splitting dim 1 at 0.28515625

New Subspace Node: lower=[0. 0.] upper=[1.         0.28515625]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.884460411702253) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4366387746096807) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (8.881784197001252e-16) < epsilon (0.001)

New Subspace Node: lower=[0.         0.28515625] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8113762050039446) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3522797723857649) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2144525167914386) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.00020153996840832633) < epsilon (0.001)
Success - new effectiveness: 3

Right expansion step 8:

Splitting dim 1 at 0.283203125

New Subspace Node: lower=[0. 0.] upper=[1.         0.28320312]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8962798541105625) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3485991699940274) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (4.440892098500626e-16) < epsilon (0.001)

New Subspace Node: lower=[0.         0.28320312] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8325115604968873) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.2963739777403047) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2366416807392633) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.00021580731063286507) < epsilon (0.001)
Success - new effectiveness: 3

Right expansion step 9:

Splitting dim 1 at 0.2822265625

New Subspace Node: lower=[0. 0.] upper=[1.         0.28222656]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7869262312488667) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3642755892091656) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (8.881784197001252e-16) < epsilon (0.001)

New Subspace Node: lower=[0.         0.28222656] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8093250346618024) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.32384336872560926) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2726861342429463) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.0015869097394629605) > epsilon (0.001)
Failure - keep old effectiveness: 3

Right expansion step 10:

Splitting dim 1 at 0.28271484375

New Subspace Node: lower=[0. 0.] upper=[1.         0.28271484]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8801997868729301) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.37000371724860504) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (8.881784197001252e-16) < epsilon (0.001)

New Subspace Node: lower=[0.         0.28271484] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8134129052235584) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.2975559203246467) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.0751697964488356) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.0008417037417016715) < epsilon (0.001)
Success - new effectiveness: 2

Right expansion step 11:

Splitting dim 1 at 0.282470703125

New Subspace Node: lower=[0. 0.] upper=[1.        0.2824707]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8448214187508813) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3735253061492645) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (4.440892098500626e-16) < epsilon (0.001)

New Subspace Node: lower=[0.        0.2824707] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8081699412318311) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.36592599646101664) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2130509065641437) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.00046728756266389837) < epsilon (0.001)
Success - new effectiveness: 2

Right expansion step 12:

Splitting dim 1 at 0.2823486328125

New Subspace Node: lower=[0. 0.] upper=[1.         0.28234863]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8758817255067393) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4069649897721537) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (6.661338147750939e-16) < epsilon (0.001)

New Subspace Node: lower=[0.         0.28234863] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.763779047644781) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3681121675985075) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2526441812799702) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.00032616874783575334) < epsilon (0.001)
Success - new effectiveness: 3

Right expansion step 13:

Splitting dim 1 at 0.28228759765625

New Subspace Node: lower=[0. 0.] upper=[1.        0.2822876]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8568877278650193) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.2618493053648423) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (4.440892098500626e-16) < epsilon (0.001)

New Subspace Node: lower=[0.        0.2822876] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8422746100167782) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.41431823971065196) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2439505333457608) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.0017334842897480662) > epsilon (0.001)
Failure - keep old effectiveness: 3

Right expansion step 14:

Splitting dim 1 at 0.282318115234375

New Subspace Node: lower=[0. 0.] upper=[1.         0.28231812]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7814105265330216) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4715663117431179) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (2.6645352591003757e-15) < epsilon (0.001)

New Subspace Node: lower=[0.         0.28231812] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7990402315601202) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.45765614297413326) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2861638563614366) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.0008268303436500535) < epsilon (0.001)
Success - new effectiveness: 2

Right expansion step 15:

Splitting dim 1 at 0.2823028564453125

New Subspace Node: lower=[0. 0.] upper=[1.         0.28230286]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8597563834564419) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4566451292335294) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
success: max error (8.881784197001252e-16) < epsilon (0.001)

New Subspace Node: lower=[0.         0.28230286] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8476959610606594) > epsilon (0.001)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3666316243928289) > epsilon (0.001)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.2171512447480444) > epsilon (0.001)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.0006745556707095091) < epsilon (0.001)
Success - new effectiveness: 2
Adding new subspaces ...
... Effectiveness: 158922379888 2


RSQTOA Statistics:
Elapsed time: 0:00:00.852460
Samples: 71680
Remaining epsilon: 0.00032544432929049096
Amount of subspaces: 2
Average reduced dimensions: 1.0

ID=[]
Leaf=False
Subdomain lower=[0. 0.]
Subdomain upper=[1. 1.]
Subdomain split_dim=1
Subdomain split_value=0.2823028564453125
Regressions:
Subdomain offset=None

ID=['1']
Leaf=True
Subdomain lower=[0. 0.]
Subdomain upper=[1.         0.28230286]
Subdomain split_dim=-1
Subdomain split_value=nan
Regressions:
-2.373992698222071e-15 * x1
Sample value=0.1659606206033086
Subdomain offset=None

ID=['2']
Leaf=True
Subdomain lower=[0.         0.28230286]
Subdomain upper=[1. 1.]
Subdomain split_dim=-1
Subdomain split_value=nan
Regressions:
-5.996860357103026 * x1 +$lb$9.997795369088298 * std::pow(x1, 2)
Sample value=0.3386660727247658
Subdomain offset=None
Model Reduction Time :: 0.8535431100000004
2022-07-18 06:44:09.232958: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-07-18 06:44:09.271285: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8aa6845d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-07-18 06:44:09.271319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Epoch 1/100
2/2 [==============================] - 0s 85ms/step - train_loss_points: 0.6729 - val_test_loss_points: 0.6492
Epoch 2/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.6411 - val_test_loss_points: 0.6211
Epoch 3/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.6150 - val_test_loss_points: 0.5986
Epoch 4/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5938 - val_test_loss_points: 0.5822
Epoch 5/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5790 - val_test_loss_points: 0.5719
Epoch 6/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.5705 - val_test_loss_points: 0.5669
Epoch 7/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5661 - val_test_loss_points: 0.5657
Epoch 8/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5660 - val_test_loss_points: 0.5666
Epoch 9/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5673 - val_test_loss_points: 0.5677
Epoch 10/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5673 - val_test_loss_points: 0.5677
Epoch 11/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5676 - val_test_loss_points: 0.5665
Epoch 12/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5661 - val_test_loss_points: 0.5641
Epoch 13/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5634 - val_test_loss_points: 0.5610
Epoch 14/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5602 - val_test_loss_points: 0.5576
Epoch 15/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5572 - val_test_loss_points: 0.5546
Epoch 16/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5537 - val_test_loss_points: 0.5522
Epoch 17/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5520 - val_test_loss_points: 0.5502
Epoch 18/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5502 - val_test_loss_points: 0.5486
Epoch 19/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5482 - val_test_loss_points: 0.5471
Epoch 20/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5469 - val_test_loss_points: 0.5456
Epoch 21/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5451 - val_test_loss_points: 0.5438
Epoch 22/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5436 - val_test_loss_points: 0.5419
Epoch 23/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5416 - val_test_loss_points: 0.5397
Epoch 24/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5390 - val_test_loss_points: 0.5374
Epoch 25/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5370 - val_test_loss_points: 0.5351
Epoch 26/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5347 - val_test_loss_points: 0.5328
Epoch 27/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5324 - val_test_loss_points: 0.5305
Epoch 28/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5301 - val_test_loss_points: 0.5282
Epoch 29/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5278 - val_test_loss_points: 0.5258
Epoch 30/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5253 - val_test_loss_points: 0.5234
Epoch 31/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5228 - val_test_loss_points: 0.5208
Epoch 32/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5203 - val_test_loss_points: 0.5181
Epoch 33/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5175 - val_test_loss_points: 0.5153
Epoch 34/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5148 - val_test_loss_points: 0.5125
Epoch 35/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5119 - val_test_loss_points: 0.5095
Epoch 36/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5087 - val_test_loss_points: 0.5064
Epoch 37/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5057 - val_test_loss_points: 0.5033
Epoch 38/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.5024 - val_test_loss_points: 0.5000
Epoch 39/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4993 - val_test_loss_points: 0.4967
Epoch 40/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4960 - val_test_loss_points: 0.4932
Epoch 41/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4926 - val_test_loss_points: 0.4897
Epoch 42/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4889 - val_test_loss_points: 0.4859
Epoch 43/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4852 - val_test_loss_points: 0.4821
Epoch 44/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4813 - val_test_loss_points: 0.4782
Epoch 45/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4770 - val_test_loss_points: 0.4742
Epoch 46/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4734 - val_test_loss_points: 0.4701
Epoch 47/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4692 - val_test_loss_points: 0.4659
Epoch 48/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4650 - val_test_loss_points: 0.4616
Epoch 49/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4607 - val_test_loss_points: 0.4572
Epoch 50/100
2/2 [==============================] - 0s 26ms/step - train_loss_points: 0.4560 - val_test_loss_points: 0.4528
Epoch 51/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4519 - val_test_loss_points: 0.4482
Epoch 52/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4473 - val_test_loss_points: 0.4436
Epoch 53/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.4426 - val_test_loss_points: 0.4388
Epoch 54/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4377 - val_test_loss_points: 0.4340
Epoch 55/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.4327 - val_test_loss_points: 0.4290
Epoch 56/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.4281 - val_test_loss_points: 0.4240
Epoch 57/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.4228 - val_test_loss_points: 0.4188
Epoch 58/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.4177 - val_test_loss_points: 0.4136
Epoch 59/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.4125 - val_test_loss_points: 0.4083
Epoch 60/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4072 - val_test_loss_points: 0.4029
Epoch 61/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.4018 - val_test_loss_points: 0.3974
Epoch 62/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.3961 - val_test_loss_points: 0.3918
Epoch 63/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.3906 - val_test_loss_points: 0.3861
Epoch 64/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.3850 - val_test_loss_points: 0.3803
Epoch 65/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3790 - val_test_loss_points: 0.3744
Epoch 66/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.3732 - val_test_loss_points: 0.3685
Epoch 67/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.3672 - val_test_loss_points: 0.3624
Epoch 68/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.3610 - val_test_loss_points: 0.3563
Epoch 69/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.3550 - val_test_loss_points: 0.3501
Epoch 70/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3488 - val_test_loss_points: 0.3438
Epoch 71/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.3425 - val_test_loss_points: 0.3375
Epoch 72/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3361 - val_test_loss_points: 0.3311
Epoch 73/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3297 - val_test_loss_points: 0.3246
Epoch 74/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.3230 - val_test_loss_points: 0.3181
Epoch 75/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3168 - val_test_loss_points: 0.3115
Epoch 76/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.3099 - val_test_loss_points: 0.3049
Epoch 77/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.3035 - val_test_loss_points: 0.2983
Epoch 78/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2969 - val_test_loss_points: 0.2916
Epoch 79/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2901 - val_test_loss_points: 0.2849
Epoch 80/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.2833 - val_test_loss_points: 0.2783
Epoch 81/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2767 - val_test_loss_points: 0.2716
Epoch 82/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.2700 - val_test_loss_points: 0.2649
Epoch 83/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.2632 - val_test_loss_points: 0.2582
Epoch 84/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2566 - val_test_loss_points: 0.2515
Epoch 85/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.2500 - val_test_loss_points: 0.2449
Epoch 86/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2437 - val_test_loss_points: 0.2384
Epoch 87/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2371 - val_test_loss_points: 0.2319
Epoch 88/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.2306 - val_test_loss_points: 0.2256
Epoch 89/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2243 - val_test_loss_points: 0.2193
Epoch 90/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2180 - val_test_loss_points: 0.2132
Epoch 91/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2120 - val_test_loss_points: 0.2072
Epoch 92/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2060 - val_test_loss_points: 0.2013
Epoch 93/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.2001 - val_test_loss_points: 0.1958
Epoch 94/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.1942 - val_test_loss_points: 0.1902
Epoch 95/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1891 - val_test_loss_points: 0.1849
Epoch 96/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1840 - val_test_loss_points: 0.1799
Epoch 97/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1788 - val_test_loss_points: 0.1750
Epoch 98/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.1754 - val_test_loss_points: 0.1708
Epoch 99/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.1698 - val_test_loss_points: 0.1664
Epoch 100/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1665 - val_test_loss_points: 0.1630
Epoch 1/100
2/2 [==============================] - 0s 62ms/step - train_loss_points: 0.7725 - val_test_loss_points: 0.7297
Epoch 2/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.7108 - val_test_loss_points: 0.6604
Epoch 3/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.6442 - val_test_loss_points: 0.6017
Epoch 4/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5904 - val_test_loss_points: 0.5676
Epoch 5/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5620 - val_test_loss_points: 0.5607
Epoch 6/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.5638 - val_test_loss_points: 0.5700
Epoch 7/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.5732 - val_test_loss_points: 0.5788
Epoch 8/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5786 - val_test_loss_points: 0.5780
Epoch 9/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5754 - val_test_loss_points: 0.5688
Epoch 10/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5654 - val_test_loss_points: 0.5563
Epoch 11/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5537 - val_test_loss_points: 0.5442
Epoch 12/100
2/2 [==============================] - 0s 25ms/step - train_loss_points: 0.5411 - val_test_loss_points: 0.5356
Epoch 13/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.5345 - val_test_loss_points: 0.5304
Epoch 14/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5289 - val_test_loss_points: 0.5277
Epoch 15/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5265 - val_test_loss_points: 0.5256
Epoch 16/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5242 - val_test_loss_points: 0.5226
Epoch 17/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.5210 - val_test_loss_points: 0.5185
Epoch 18/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.5166 - val_test_loss_points: 0.5133
Epoch 19/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5111 - val_test_loss_points: 0.5075
Epoch 20/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5052 - val_test_loss_points: 0.5018
Epoch 21/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4999 - val_test_loss_points: 0.4965
Epoch 22/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.4939 - val_test_loss_points: 0.4916
Epoch 23/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4895 - val_test_loss_points: 0.4869
Epoch 24/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4850 - val_test_loss_points: 0.4820
Epoch 25/100
2/2 [==============================] - 0s 28ms/step - train_loss_points: 0.4797 - val_test_loss_points: 0.4768
Epoch 26/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.4751 - val_test_loss_points: 0.4714
Epoch 27/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4695 - val_test_loss_points: 0.4657
Epoch 28/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4640 - val_test_loss_points: 0.4601
Epoch 29/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4581 - val_test_loss_points: 0.4545
Epoch 30/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.4522 - val_test_loss_points: 0.4489
Epoch 31/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4470 - val_test_loss_points: 0.4433
Epoch 32/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4411 - val_test_loss_points: 0.4375
Epoch 33/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4352 - val_test_loss_points: 0.4315
Epoch 34/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4295 - val_test_loss_points: 0.4254
Epoch 35/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4233 - val_test_loss_points: 0.4192
Epoch 36/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.4171 - val_test_loss_points: 0.4130
Epoch 37/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.4107 - val_test_loss_points: 0.4068
Epoch 38/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.4046 - val_test_loss_points: 0.4005
Epoch 39/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.3982 - val_test_loss_points: 0.3942
Epoch 40/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3920 - val_test_loss_points: 0.3878
Epoch 41/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3856 - val_test_loss_points: 0.3814
Epoch 42/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.3789 - val_test_loss_points: 0.3750
Epoch 43/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3727 - val_test_loss_points: 0.3685
Epoch 44/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3663 - val_test_loss_points: 0.3620
Epoch 45/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3594 - val_test_loss_points: 0.3556
Epoch 46/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.3533 - val_test_loss_points: 0.3491
Epoch 47/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3469 - val_test_loss_points: 0.3426
Epoch 48/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3402 - val_test_loss_points: 0.3361
Epoch 49/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.3337 - val_test_loss_points: 0.3297
Epoch 50/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3273 - val_test_loss_points: 0.3232
Epoch 51/100
2/2 [==============================] - 0s 26ms/step - train_loss_points: 0.3209 - val_test_loss_points: 0.3168
Epoch 52/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3144 - val_test_loss_points: 0.3104
Epoch 53/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3081 - val_test_loss_points: 0.3040
Epoch 54/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3017 - val_test_loss_points: 0.2976
Epoch 55/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.2953 - val_test_loss_points: 0.2913
Epoch 56/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2891 - val_test_loss_points: 0.2850
Epoch 57/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.2828 - val_test_loss_points: 0.2788
Epoch 58/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2764 - val_test_loss_points: 0.2727
Epoch 59/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2706 - val_test_loss_points: 0.2667
Epoch 60/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2644 - val_test_loss_points: 0.2607
Epoch 61/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.2585 - val_test_loss_points: 0.2548
Epoch 62/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2528 - val_test_loss_points: 0.2491
Epoch 63/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.2469 - val_test_loss_points: 0.2434
Epoch 64/100
2/2 [==============================] - 0s 25ms/step - train_loss_points: 0.2414 - val_test_loss_points: 0.2379
Epoch 65/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2359 - val_test_loss_points: 0.2325
Epoch 66/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.2303 - val_test_loss_points: 0.2273
Epoch 67/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2254 - val_test_loss_points: 0.2222
Epoch 68/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.2204 - val_test_loss_points: 0.2173
Epoch 69/100
2/2 [==============================] - 0s 25ms/step - train_loss_points: 0.2155 - val_test_loss_points: 0.2127
Epoch 70/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2111 - val_test_loss_points: 0.2082
Epoch 71/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2065 - val_test_loss_points: 0.2040
Epoch 72/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.2024 - val_test_loss_points: 0.2000
Epoch 73/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1985 - val_test_loss_points: 0.1963
Epoch 74/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1949 - val_test_loss_points: 0.1929
Epoch 75/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.1916 - val_test_loss_points: 0.1896
Epoch 76/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.1878 - val_test_loss_points: 0.1867
Epoch 77/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.1854 - val_test_loss_points: 0.1841
Epoch 78/100
2/2 [==============================] - 0s 30ms/step - train_loss_points: 0.1831 - val_test_loss_points: 0.1816
Epoch 79/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1807 - val_test_loss_points: 0.1794
Epoch 80/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1785 - val_test_loss_points: 0.1776
Epoch 81/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.1768 - val_test_loss_points: 0.1757
Epoch 82/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1751 - val_test_loss_points: 0.1741
Epoch 83/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1735 - val_test_loss_points: 0.1728
Epoch 84/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.1723 - val_test_loss_points: 0.1717
Epoch 85/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1710 - val_test_loss_points: 0.1704
Epoch 86/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1701 - val_test_loss_points: 0.1694
Epoch 87/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.1693 - val_test_loss_points: 0.1688
Epoch 88/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1685 - val_test_loss_points: 0.1678
Epoch 89/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1675 - val_test_loss_points: 0.1672
Epoch 90/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.1668 - val_test_loss_points: 0.1664
Epoch 91/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1660 - val_test_loss_points: 0.1655
Epoch 92/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1654 - val_test_loss_points: 0.1649
Epoch 93/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.1647 - val_test_loss_points: 0.1642
Epoch 94/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.1637 - val_test_loss_points: 0.1636
Epoch 95/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.1637 - val_test_loss_points: 0.1629
Epoch 96/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.1627 - val_test_loss_points: 0.1623
Epoch 97/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1620 - val_test_loss_points: 0.1616
Epoch 98/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1616 - val_test_loss_points: 0.1610
Epoch 99/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.1608 - val_test_loss_points: 0.1603
Epoch 100/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1599 - val_test_loss_points: 0.1596
Residual Domain model training time :: 16.468850685
idx = 0
idx = 1
Mean Squared Error (Training Data)::  0.04512109140029398
Root Mean Squared Error (Training Data)::  0.2124172577741601
idx = 0
idx = 1
Total testing time :: 0.19891572399999902
Mean Squared Error (Out of sample test)::  0.045672141412949556
Root Mean Squared Error (Out of sample test)::  0.2137104148443626

Process finished with exit code 0
