/opt/anaconda3/envs/rsqtoa/bin/python /Users/ashish/work/thesis/rsqtoa/case_studies/python/test/10000/nearest_neighbour/show_case_nn.py
Total compile time :: 0.0029218819999998757

New Subspace Node: lower=[0. 0.] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.831390088887451) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.43230627555382073) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.8909307141410592) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.48977880118421524) > epsilon (0.13)

Subspace division depth: 1

Splitting dim 0 at 0.5

New Subspace Node: lower=[0. 0.] upper=[0.5 1. ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.15599662498836686) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.10245315263238464) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.1136615489553874) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.43872897137420175) > epsilon (0.13)

New Subspace Node: lower=[0.5 0. ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.23440782691179862) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.17926373399454176) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.1556357538528674) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3970252176451967) > epsilon (0.13)
Effectiveness: 2 1

Left expansion step 1:

Splitting dim 0 at 0.75

New Subspace Node: lower=[0. 0.] upper=[0.75 1.  ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.6422434055640891) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.2491222611352435) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0959255825841874) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3903299346331863) > epsilon (0.13)

New Subspace Node: lower=[0.75 0.  ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.14333592310951837) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.04111796144952695) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.247351792862097) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.42268313611310937) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 2:

Splitting dim 0 at 0.625

New Subspace Node: lower=[0. 0.] upper=[0.625 1.   ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.4245963519812044) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.20828311173602687) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.1772423288157254) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.39654338292634694) > epsilon (0.13)

New Subspace Node: lower=[0.625 0.   ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.23101043856040504) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.0683111804480312) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.1926435471518295) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.37882759281089173) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 3:

Splitting dim 0 at 0.5625

New Subspace Node: lower=[0. 0.] upper=[0.5625 1.    ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2952566542828312) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.14890966068243516) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.9788485831104818) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.36596433898013503) > epsilon (0.13)

New Subspace Node: lower=[0.5625 0.    ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2146731665864079) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.1336921481858937) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.318455862681178) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.46352923509297717) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 4:

Splitting dim 0 at 0.53125

New Subspace Node: lower=[0. 0.] upper=[0.53125 1.     ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.17253717017548365) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.12017149794424586) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.992738981507948) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.4013989615431275) > epsilon (0.13)

New Subspace Node: lower=[0.53125 0.     ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.23992879684840185) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.167133882328395) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0660227793461168) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.40784389869731097) > epsilon (0.13)
Success - new effectiveness: 2

Left expansion step 5:

Splitting dim 0 at 0.546875

New Subspace Node: lower=[0. 0.] upper=[0.546875 1.      ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.21881782202301014) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.12933189647713572) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0842453498574365) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3834463942302797) > epsilon (0.13)

New Subspace Node: lower=[0.546875 0.      ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.21805416441134362) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.10684053672228999) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.285377336623588) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.4714220214065987) > epsilon (0.13)
Success - new effectiveness: 2

Left expansion step 6:

Splitting dim 0 at 0.5546875

New Subspace Node: lower=[0. 0.] upper=[0.5546875 1.       ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.24750096785359865) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.12795825641522107) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.2264291401847984) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.426785666455731) > epsilon (0.13)

New Subspace Node: lower=[0.5546875 0.       ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.21483452952060134) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.13010004057770264) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.2084648479145765) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3545647043064175) > epsilon (0.13)
Success - new effectiveness: 2

Left expansion step 7:

Splitting dim 0 at 0.55859375

New Subspace Node: lower=[0. 0.] upper=[0.55859375 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2863261372334591) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.1730922853123591) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.8498429809939458) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3813920708034706) > epsilon (0.13)

New Subspace Node: lower=[0.55859375 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.23489994913289625) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.12942125363878) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.105505933070621) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.44984890015300105) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 8:

Splitting dim 0 at 0.556640625

New Subspace Node: lower=[0. 0.] upper=[0.55664062 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.24790267842662495) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.14019410017661826) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0142543177732137) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3691504578356124) > epsilon (0.13)

New Subspace Node: lower=[0.55664062 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2396526359870137) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.13206968011413833) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.33044465381893) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.44571200352760454) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 9:

Splitting dim 0 at 0.5556640625

New Subspace Node: lower=[0. 0.] upper=[0.55566406 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2760482405133109) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.18031071932149345) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.1430261782567603) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.44567516459458645) > epsilon (0.13)

New Subspace Node: lower=[0.55566406 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.22075315202054657) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.14867233514288958) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0714297051159267) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3808552485791121) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 10:

Splitting dim 0 at 0.55517578125

New Subspace Node: lower=[0. 0.] upper=[0.55517578 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.25502169840290545) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.1420086369267355) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.2053087345805764) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.2973354131934909) > epsilon (0.13)

New Subspace Node: lower=[0.55517578 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.22836111146704186) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.13284629102911705) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.1313544766790846) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3434755649237986) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 11:

Splitting dim 0 at 0.554931640625

New Subspace Node: lower=[0. 0.] upper=[0.55493164 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.27707185196976436) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.13929973835991483) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0721320409927464) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.4984500940117509) > epsilon (0.13)

New Subspace Node: lower=[0.55493164 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.18788134065882112) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.10302075381779208) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.9505117308922455) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.4213063123692242) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 12:

Splitting dim 0 at 0.5548095703125

New Subspace Node: lower=[0. 0.] upper=[0.55480957 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.24315391085244364) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.133546235266349) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0377040770477564) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.40520311858963676) > epsilon (0.13)

New Subspace Node: lower=[0.55480957 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.21007665641769036) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.10842924252833219) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0025550504512086) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.4125969463594581) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 13:

Splitting dim 0 at 0.55474853515625

New Subspace Node: lower=[0. 0.] upper=[0.55474854 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2695551596045571) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.13740230208920767) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.195452873464756) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.37789097605622013) > epsilon (0.13)

New Subspace Node: lower=[0.55474854 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.22674344928713497) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.13949359251877658) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.2252254685649486) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.44699161787265107) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 14:

Splitting dim 0 at 0.554718017578125

New Subspace Node: lower=[0. 0.] upper=[0.55471802 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2828828929146554) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.1299711293683421) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (1.8145642976874115) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3964019747457239) > epsilon (0.13)

New Subspace Node: lower=[0.55471802 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.22191252559275476) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.11407480500232747) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0237615410570067) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.4046868117179794) > epsilon (0.13)
Success - new effectiveness: 2

Left expansion step 15:

Splitting dim 0 at 0.5547332763671875

New Subspace Node: lower=[0. 0.] upper=[0.55473328 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2639750457442549) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.1561762544952039) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0847926792006777) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3824667478920061) > epsilon (0.13)

New Subspace Node: lower=[0.55473328 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.24495958697945097) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.1319759237418605) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.1433814343988704) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.36769766667454307) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 16:

Splitting dim 0 at 0.5547256469726562

New Subspace Node: lower=[0. 0.] upper=[0.55472565 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.28151672240585013) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.11940574739805765) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.210223652450726) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.430488922818558) > epsilon (0.13)

New Subspace Node: lower=[0.55472565 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.24157025814973854) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.18073407262382357) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0596627827589247) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.33282368619606095) > epsilon (0.13)
Success - new effectiveness: 2

Left expansion step 17:

Splitting dim 0 at 0.5547294616699219

New Subspace Node: lower=[0. 0.] upper=[0.55472946 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.27942119959742406) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.1372467586249546) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.250794717354692) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.45833616578721603) > epsilon (0.13)

New Subspace Node: lower=[0.55472946 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.20824239325237004) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.12584941000547012) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.1134321466060086) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.296309501890728) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 18:

Splitting dim 0 at 0.5547275543212891

New Subspace Node: lower=[0. 0.] upper=[0.55472755 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2449737947782813) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.20803489680770282) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.131881256777855) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3707142748123158) > epsilon (0.13)

New Subspace Node: lower=[0.55472755 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.22393043089692277) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.107900460673656) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.225936182054752) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.36947747508909967) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 19:

Splitting dim 0 at 0.5547266006469727

New Subspace Node: lower=[0. 0.] upper=[0.5547266 1.       ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2649963127072681) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
success: max error (0.12551123170534684) < epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.2058541089109385) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.33878665685501375) > epsilon (0.13)

New Subspace Node: lower=[0.5547266 0.       ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.210799180972304) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.15476591788581917) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.2080554821216314) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.39709429403609864) > epsilon (0.13)
Success - new effectiveness: 2

Left expansion step 20:

Splitting dim 0 at 0.5547270774841309

New Subspace Node: lower=[0. 0.] upper=[0.55472708 1.        ]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.2598926590484574) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.14631173043020418) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.2338259877554734) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.4097550276347093) > epsilon (0.13)

New Subspace Node: lower=[0.55472708 0.        ] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.22757077901277523) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.13206135277850173) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (2.0323853262157487) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.3909579236378382) > epsilon (0.13)
Failure - keep old effectiveness: 2

Splitting dim 1 at 0.5

New Subspace Node: lower=[0. 0.] upper=[1.  0.5]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8641878641453713) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4631145333403528) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.2762551455534079) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.12259246255788248) < epsilon (0.13)

New Subspace Node: lower=[0.  0.5] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7432662026143793) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3766233535662571) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.6530150976680158) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.15135023445885754) > epsilon (0.13)
Effectiveness: 2 1

Left expansion step 1:

Splitting dim 1 at 0.75

New Subspace Node: lower=[0. 0.] upper=[1.   0.75]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8832783859880307) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4133413840130311) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.9740711458250657) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.2930535632922502) > epsilon (0.13)

New Subspace Node: lower=[0.   0.75] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7790512531637717) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.34464996743624177) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.19478954261580217) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.17885880339687255) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 2:

Splitting dim 1 at 0.625

New Subspace Node: lower=[0. 0.] upper=[1.    0.625]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8860002492732684) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.36140416113689033) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.6565288590958365) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.2608096842560812) > epsilon (0.13)

New Subspace Node: lower=[0.    0.625] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8859334353467325) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.2900803073503919) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.41284102339651785) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.125600437176546) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 3:

Splitting dim 1 at 0.5625

New Subspace Node: lower=[0. 0.] upper=[1.     0.5625]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8027263074958426) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4049375343923942) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.4774729844071737) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.15174235409260017) > epsilon (0.13)

New Subspace Node: lower=[0.     0.5625] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8377922936758173) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3719319140332109) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.4483511822882784) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.12202269674297472) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 4:

Splitting dim 1 at 0.53125

New Subspace Node: lower=[0. 0.] upper=[1.      0.53125]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8895322437270567) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4019798503149383) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.3358081165819029) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.1294991068337228) < epsilon (0.13)

New Subspace Node: lower=[0.      0.53125] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8585673146783597) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.39944032075837654) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5586713506812493) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.11841219899015787) < epsilon (0.13)
Success - new effectiveness: 2

Left expansion step 5:

Splitting dim 1 at 0.546875

New Subspace Node: lower=[0. 0.] upper=[1.       0.546875]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7990696518972495) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4337103750376001) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.41610199234348144) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.15195465860658386) > epsilon (0.13)

New Subspace Node: lower=[0.       0.546875] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8314827644318017) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.2842545523245543) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5317917196022597) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.163023212103794) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 6:

Splitting dim 1 at 0.5390625

New Subspace Node: lower=[0. 0.] upper=[1.        0.5390625]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8394524828257883) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.31344412084265505) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.33668879187323153) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.11802338773048926) < epsilon (0.13)

New Subspace Node: lower=[0.        0.5390625] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8104519012132831) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3712000137380187) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5403382819007208) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.11811079806111202) < epsilon (0.13)
Success - new effectiveness: 2

Left expansion step 7:

Splitting dim 1 at 0.54296875

New Subspace Node: lower=[0. 0.] upper=[1.         0.54296875]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8396011547259372) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4497525362591588) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.4120866846258906) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.1369807575916635) > epsilon (0.13)

New Subspace Node: lower=[0.         0.54296875] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8134417114288608) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.41807997548768894) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5487607560001369) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.11643605877288365) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 8:

Splitting dim 1 at 0.541015625

New Subspace Node: lower=[0. 0.] upper=[1.         0.54101562]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.9148540268178333) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.42626823499122746) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.4135705455192782) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.17039391932370607) > epsilon (0.13)

New Subspace Node: lower=[0.         0.54101562] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8703243889478776) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4294692897465813) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5321987236114314) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.16051613065793902) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 9:

Splitting dim 1 at 0.5400390625

New Subspace Node: lower=[0. 0.] upper=[1.         0.54003906]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8603784827522882) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4412010016956631) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.36380601921432154) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.14437624602581467) > epsilon (0.13)

New Subspace Node: lower=[0.         0.54003906] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8819739385691969) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.41013627965021193) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5148706617966163) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.11484370458007653) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 10:

Splitting dim 1 at 0.53955078125

New Subspace Node: lower=[0. 0.] upper=[1.         0.53955078]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8975550967137211) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3760810193298938) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.3936182672098165) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.14674503736236444) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53955078] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8616788419459418) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.35868267545434573) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.49075556772726436) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.09492116889292568) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 11:

Splitting dim 1 at 0.539306640625

New Subspace Node: lower=[0. 0.] upper=[1.         0.53930664]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8274361628858529) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.33375232610804506) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.3976673814136138) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.14744794020616636) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53930664] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.7857508009553467) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.40366167664819796) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5181117717783144) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.13439451032253213) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 12:

Splitting dim 1 at 0.5391845703125

New Subspace Node: lower=[0. 0.] upper=[1.         0.53918457]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8389722122728989) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3452800620086529) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.41004921485834167) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.17471195825300923) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53918457] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8988955110801866) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3999869525765398) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5260112666602366) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.1439024806404543) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 13:

Splitting dim 1 at 0.53912353515625

New Subspace Node: lower=[0. 0.] upper=[1.         0.53912354]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8514866076229337) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3966408925421514) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.4250656016764345) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.13418862058993497) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53912354] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8152300627363416) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3021244277584767) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5933290850577282) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.11967053748664558) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 14:

Splitting dim 1 at 0.539093017578125

New Subspace Node: lower=[0. 0.] upper=[1.         0.53909302]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8790376440656438) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4502660515690218) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.4053388622301224) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.21309780223901065) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53909302] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8818490494557576) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4071151567596605) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5460887335388938) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.11032099747136304) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 15:

Splitting dim 1 at 0.5390777587890625

New Subspace Node: lower=[0. 0.] upper=[1.         0.53907776]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8977041950890898) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.32856520819847934) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.37126848507206) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.18394525641019221) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53907776] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8373645752492846) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.44110680880758446) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5624871906972668) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.13544098567181884) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 16:

Splitting dim 1 at 0.5390701293945312

New Subspace Node: lower=[0. 0.] upper=[1.         0.53907013]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8107710187668768) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.47231952557630263) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.4192845865186987) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.15982262109601386) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53907013] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.879061862358486) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.45149626007171495) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.51487659399023) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.16374137932500332) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 17:

Splitting dim 1 at 0.5390663146972656

New Subspace Node: lower=[0. 0.] upper=[1.         0.53906631]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8957020540087703) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.3284945602768108) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.36966117129244336) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.14196591780140566) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53906631] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8595859137304309) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4269612895197539) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5603733159380972) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.11302083359122062) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 18:

Splitting dim 1 at 0.5390644073486328

New Subspace Node: lower=[0. 0.] upper=[1.         0.53906441]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8011964756155763) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4068563542277539) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.3731505720157273) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.1616656754441883) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53906441] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8913270594361267) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.413042262449995) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.505860812409022) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.1021504485597049) < epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 19:

Splitting dim 1 at 0.5390634536743164

New Subspace Node: lower=[0. 0.] upper=[1.         0.53906345]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8832498477022308) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.39805909075916057) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.39899917430152376) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.16699058542754042) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53906345] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8370085180693017) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.41927715577088165) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.559370461911822) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.14249279288576044) > epsilon (0.13)
Failure - keep old effectiveness: 2

Left expansion step 20:

Splitting dim 1 at 0.5390629768371582

New Subspace Node: lower=[0. 0.] upper=[1.         0.53906298]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.8169526843582302) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.43483988780020066) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.3513609458754894) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
fail: max error (0.1597113928562517) > epsilon (0.13)

New Subspace Node: lower=[0.         0.53906298] upper=[1. 1.]
Dimension 0 taylor (order = 1) regression ...
fail: max error (0.9009105365328369) > epsilon (0.13)
Dimension 0 taylor (order = 2) regression ...
fail: max error (0.4576859813656835) > epsilon (0.13)
Dimension 1 taylor (order = 1) regression ...
fail: max error (0.5129154225728971) > epsilon (0.13)
Dimension 1 taylor (order = 2) regression ...
success: max error (0.09541974833484179) < epsilon (0.13)
Failure - keep old effectiveness: 2
Adding new subspaces ...
... Effectiveness: 2 2


RSQTOA Statistics:
Elapsed time: 0:00:15.426518
Samples: 227800
Remaining epsilon: 0.011889201938887983
Amount of subspaces: 2
Average reduced dimensions: 1.0

ID=[]
Leaf=False
Subdomain lower=[0. 0.]
Subdomain upper=[1. 1.]
Subdomain split_dim=1
Subdomain split_value=0.5390629768371582
Regressions:
Subdomain offset=None

ID=['1']
Leaf=True
Subdomain lower=[0. 0.]
Subdomain upper=[1.        0.5390625]
Subdomain split_dim=-1
Subdomain split_value=nan
Regressions:
-1.4461549580543382 * x1 +$lb$4.045129278376367 * std::pow(x1, 2)
Sample value=0.4776937469631697
Subdomain offset=None

ID=['2']
Leaf=True
Subdomain lower=[0.        0.5390625]
Subdomain upper=[1. 1.]
Subdomain split_dim=-1
Subdomain split_value=nan
Regressions:
-5.763342371122453 * x1 +$lb$9.831191635894765 * std::pow(x1, 2)
Sample value=0.7252067590296403
Subdomain offset=None
Model Reduction time :: 15.433978478
2022-07-18 06:53:49.911453: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-07-18 06:53:49.926456: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe0b40c6e40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-07-18 06:53:49.926471: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Epoch 1/100
2/2 [==============================] - 0s 89ms/step - train_loss_points: 0.7219 - val_test_loss_points: 0.6953
Epoch 2/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.6870 - val_test_loss_points: 0.6631
Epoch 3/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.6557 - val_test_loss_points: 0.6350
Epoch 4/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.6282 - val_test_loss_points: 0.6114
Epoch 5/100
2/2 [==============================] - 0s 28ms/step - train_loss_points: 0.6064 - val_test_loss_points: 0.5925
Epoch 6/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5884 - val_test_loss_points: 0.5783
Epoch 7/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5755 - val_test_loss_points: 0.5685
Epoch 8/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5666 - val_test_loss_points: 0.5625
Epoch 9/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5617 - val_test_loss_points: 0.5596
Epoch 10/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5597 - val_test_loss_points: 0.5587
Epoch 11/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5589 - val_test_loss_points: 0.5588
Epoch 12/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5589 - val_test_loss_points: 0.5590
Epoch 13/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5579 - val_test_loss_points: 0.5588
Epoch 14/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5586 - val_test_loss_points: 0.5581
Epoch 15/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5575 - val_test_loss_points: 0.5566
Epoch 16/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5560 - val_test_loss_points: 0.5547
Epoch 17/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5538 - val_test_loss_points: 0.5523
Epoch 18/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5517 - val_test_loss_points: 0.5499
Epoch 19/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5490 - val_test_loss_points: 0.5475
Epoch 20/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5468 - val_test_loss_points: 0.5453
Epoch 21/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5446 - val_test_loss_points: 0.5433
Epoch 22/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5423 - val_test_loss_points: 0.5415
Epoch 23/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5410 - val_test_loss_points: 0.5398
Epoch 24/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5394 - val_test_loss_points: 0.5383
Epoch 25/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5377 - val_test_loss_points: 0.5367
Epoch 26/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5359 - val_test_loss_points: 0.5351
Epoch 27/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5345 - val_test_loss_points: 0.5334
Epoch 28/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5329 - val_test_loss_points: 0.5316
Epoch 29/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.5312 - val_test_loss_points: 0.5297
Epoch 30/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5293 - val_test_loss_points: 0.5278
Epoch 31/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5270 - val_test_loss_points: 0.5259
Epoch 32/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5255 - val_test_loss_points: 0.5239
Epoch 33/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5227 - val_test_loss_points: 0.5219
Epoch 34/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5214 - val_test_loss_points: 0.5199
Epoch 35/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5193 - val_test_loss_points: 0.5179
Epoch 36/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5173 - val_test_loss_points: 0.5158
Epoch 37/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5153 - val_test_loss_points: 0.5137
Epoch 38/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5130 - val_test_loss_points: 0.5115
Epoch 39/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5110 - val_test_loss_points: 0.5093
Epoch 40/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5086 - val_test_loss_points: 0.5069
Epoch 41/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5063 - val_test_loss_points: 0.5046
Epoch 42/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5037 - val_test_loss_points: 0.5021
Epoch 43/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5015 - val_test_loss_points: 0.4995
Epoch 44/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4987 - val_test_loss_points: 0.4969
Epoch 45/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.4961 - val_test_loss_points: 0.4941
Epoch 46/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.4934 - val_test_loss_points: 0.4913
Epoch 47/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4905 - val_test_loss_points: 0.4883
Epoch 48/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4875 - val_test_loss_points: 0.4851
Epoch 49/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4842 - val_test_loss_points: 0.4819
Epoch 50/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4810 - val_test_loss_points: 0.4785
Epoch 51/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4775 - val_test_loss_points: 0.4751
Epoch 52/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4742 - val_test_loss_points: 0.4715
Epoch 53/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4706 - val_test_loss_points: 0.4679
Epoch 54/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.4668 - val_test_loss_points: 0.4641
Epoch 55/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4629 - val_test_loss_points: 0.4602
Epoch 56/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4591 - val_test_loss_points: 0.4562
Epoch 57/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.4552 - val_test_loss_points: 0.4522
Epoch 58/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.4510 - val_test_loss_points: 0.4480
Epoch 59/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4467 - val_test_loss_points: 0.4437
Epoch 60/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.4425 - val_test_loss_points: 0.4393
Epoch 61/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.4379 - val_test_loss_points: 0.4347
Epoch 62/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4335 - val_test_loss_points: 0.4301
Epoch 63/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4286 - val_test_loss_points: 0.4253
Epoch 64/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4239 - val_test_loss_points: 0.4205
Epoch 65/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.4191 - val_test_loss_points: 0.4155
Epoch 66/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.4140 - val_test_loss_points: 0.4104
Epoch 67/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4089 - val_test_loss_points: 0.4051
Epoch 68/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.4037 - val_test_loss_points: 0.3998
Epoch 69/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.3981 - val_test_loss_points: 0.3943
Epoch 70/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.3927 - val_test_loss_points: 0.3887
Epoch 71/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3871 - val_test_loss_points: 0.3830
Epoch 72/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3813 - val_test_loss_points: 0.3771
Epoch 73/100
2/2 [==============================] - 0s 26ms/step - train_loss_points: 0.3755 - val_test_loss_points: 0.3711
Epoch 74/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.3695 - val_test_loss_points: 0.3650
Epoch 75/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3633 - val_test_loss_points: 0.3588
Epoch 76/100
2/2 [==============================] - 0s 25ms/step - train_loss_points: 0.3570 - val_test_loss_points: 0.3524
Epoch 77/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3505 - val_test_loss_points: 0.3459
Epoch 78/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3440 - val_test_loss_points: 0.3392
Epoch 79/100
2/2 [==============================] - 0s 25ms/step - train_loss_points: 0.3373 - val_test_loss_points: 0.3325
Epoch 80/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3305 - val_test_loss_points: 0.3255
Epoch 81/100
2/2 [==============================] - 0s 48ms/step - train_loss_points: 0.3235 - val_test_loss_points: 0.3185
Epoch 82/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.3164 - val_test_loss_points: 0.3113
Epoch 83/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.3093 - val_test_loss_points: 0.3039
Epoch 84/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.3019 - val_test_loss_points: 0.2965
Epoch 85/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2944 - val_test_loss_points: 0.2890
Epoch 86/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2867 - val_test_loss_points: 0.2813
Epoch 87/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.2792 - val_test_loss_points: 0.2735
Epoch 88/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.2713 - val_test_loss_points: 0.2656
Epoch 89/100
2/2 [==============================] - 0s 24ms/step - train_loss_points: 0.2633 - val_test_loss_points: 0.2577
Epoch 90/100
2/2 [==============================] - 0s 28ms/step - train_loss_points: 0.2553 - val_test_loss_points: 0.2496
Epoch 91/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2473 - val_test_loss_points: 0.2414
Epoch 92/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2389 - val_test_loss_points: 0.2332
Epoch 93/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.2309 - val_test_loss_points: 0.2250
Epoch 94/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.2227 - val_test_loss_points: 0.2168
Epoch 95/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2143 - val_test_loss_points: 0.2086
Epoch 96/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.2061 - val_test_loss_points: 0.2005
Epoch 97/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1980 - val_test_loss_points: 0.1924
Epoch 98/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1898 - val_test_loss_points: 0.1844
Epoch 99/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.1818 - val_test_loss_points: 0.1766
Epoch 100/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1742 - val_test_loss_points: 0.1690
Epoch 1/100
2/2 [==============================] - 0s 49ms/step - train_loss_points: 0.6584 - val_test_loss_points: 0.6230
Epoch 2/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.6109 - val_test_loss_points: 0.5807
Epoch 3/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.5746 - val_test_loss_points: 0.5661
Epoch 4/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5668 - val_test_loss_points: 0.5743
Epoch 5/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5778 - val_test_loss_points: 0.5814
Epoch 6/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5810 - val_test_loss_points: 0.5753
Epoch 7/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.5717 - val_test_loss_points: 0.5615
Epoch 8/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5578 - val_test_loss_points: 0.5479
Epoch 9/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.5451 - val_test_loss_points: 0.5402
Epoch 10/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5383 - val_test_loss_points: 0.5373
Epoch 11/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5367 - val_test_loss_points: 0.5355
Epoch 12/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.5348 - val_test_loss_points: 0.5318
Epoch 13/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.5300 - val_test_loss_points: 0.5251
Epoch 14/100
2/2 [==============================] - 0s 17ms/step - train_loss_points: 0.5231 - val_test_loss_points: 0.5174
Epoch 15/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.5153 - val_test_loss_points: 0.5106
Epoch 16/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5085 - val_test_loss_points: 0.5052
Epoch 17/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.5036 - val_test_loss_points: 0.5004
Epoch 18/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.4989 - val_test_loss_points: 0.4953
Epoch 19/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4936 - val_test_loss_points: 0.4893
Epoch 20/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4876 - val_test_loss_points: 0.4827
Epoch 21/100
2/2 [==============================] - 0s 29ms/step - train_loss_points: 0.4806 - val_test_loss_points: 0.4761
Epoch 22/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4741 - val_test_loss_points: 0.4699
Epoch 23/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4685 - val_test_loss_points: 0.4640
Epoch 24/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4623 - val_test_loss_points: 0.4578
Epoch 25/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.4563 - val_test_loss_points: 0.4514
Epoch 26/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4495 - val_test_loss_points: 0.4446
Epoch 27/100
2/2 [==============================] - 0s 25ms/step - train_loss_points: 0.4425 - val_test_loss_points: 0.4378
Epoch 28/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4359 - val_test_loss_points: 0.4312
Epoch 29/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4292 - val_test_loss_points: 0.4245
Epoch 30/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.4226 - val_test_loss_points: 0.4175
Epoch 31/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.4158 - val_test_loss_points: 0.4104
Epoch 32/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.4085 - val_test_loss_points: 0.4031
Epoch 33/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.4011 - val_test_loss_points: 0.3958
Epoch 34/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3934 - val_test_loss_points: 0.3883
Epoch 35/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3863 - val_test_loss_points: 0.3808
Epoch 36/100
2/2 [==============================] - 0s 34ms/step - train_loss_points: 0.3783 - val_test_loss_points: 0.3729
Epoch 37/100
2/2 [==============================] - 0s 26ms/step - train_loss_points: 0.3709 - val_test_loss_points: 0.3649
Epoch 38/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3625 - val_test_loss_points: 0.3568
Epoch 39/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.3544 - val_test_loss_points: 0.3486
Epoch 40/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3462 - val_test_loss_points: 0.3401
Epoch 41/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3378 - val_test_loss_points: 0.3314
Epoch 42/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.3291 - val_test_loss_points: 0.3226
Epoch 43/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.3200 - val_test_loss_points: 0.3136
Epoch 44/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.3108 - val_test_loss_points: 0.3045
Epoch 45/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.3019 - val_test_loss_points: 0.2950
Epoch 46/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2925 - val_test_loss_points: 0.2854
Epoch 47/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.2825 - val_test_loss_points: 0.2756
Epoch 48/100
2/2 [==============================] - 0s 25ms/step - train_loss_points: 0.2728 - val_test_loss_points: 0.2655
Epoch 49/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2626 - val_test_loss_points: 0.2552
Epoch 50/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2523 - val_test_loss_points: 0.2447
Epoch 51/100
2/2 [==============================] - 0s 28ms/step - train_loss_points: 0.2418 - val_test_loss_points: 0.2343
Epoch 52/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2313 - val_test_loss_points: 0.2242
Epoch 53/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2213 - val_test_loss_points: 0.2144
Epoch 54/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.2113 - val_test_loss_points: 0.2050
Epoch 55/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.2022 - val_test_loss_points: 0.1960
Epoch 56/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1936 - val_test_loss_points: 0.1877
Epoch 57/100
2/2 [==============================] - 0s 29ms/step - train_loss_points: 0.1852 - val_test_loss_points: 0.1801
Epoch 58/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1778 - val_test_loss_points: 0.1733
Epoch 59/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1710 - val_test_loss_points: 0.1671
Epoch 60/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.1652 - val_test_loss_points: 0.1620
Epoch 61/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1602 - val_test_loss_points: 0.1576
Epoch 62/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1563 - val_test_loss_points: 0.1540
Epoch 63/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.1526 - val_test_loss_points: 0.1513
Epoch 64/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1504 - val_test_loss_points: 0.1490
Epoch 65/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1478 - val_test_loss_points: 0.1470
Epoch 66/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.1462 - val_test_loss_points: 0.1455
Epoch 67/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1446 - val_test_loss_points: 0.1440
Epoch 68/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1433 - val_test_loss_points: 0.1426
Epoch 69/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.1418 - val_test_loss_points: 0.1413
Epoch 70/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1406 - val_test_loss_points: 0.1397
Epoch 71/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1398 - val_test_loss_points: 0.1384
Epoch 72/100
2/2 [==============================] - 0s 26ms/step - train_loss_points: 0.1377 - val_test_loss_points: 0.1371
Epoch 73/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1362 - val_test_loss_points: 0.1355
Epoch 74/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1353 - val_test_loss_points: 0.1342
Epoch 75/100
2/2 [==============================] - 0s 28ms/step - train_loss_points: 0.1337 - val_test_loss_points: 0.1330
Epoch 76/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.1322 - val_test_loss_points: 0.1314
Epoch 77/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1308 - val_test_loss_points: 0.1304
Epoch 78/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1295 - val_test_loss_points: 0.1290
Epoch 79/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1282 - val_test_loss_points: 0.1280
Epoch 80/100
2/2 [==============================] - 0s 26ms/step - train_loss_points: 0.1273 - val_test_loss_points: 0.1268
Epoch 81/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1266 - val_test_loss_points: 0.1259
Epoch 82/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1251 - val_test_loss_points: 0.1250
Epoch 83/100
2/2 [==============================] - 0s 29ms/step - train_loss_points: 0.1243 - val_test_loss_points: 0.1238
Epoch 84/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.1230 - val_test_loss_points: 0.1230
Epoch 85/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1227 - val_test_loss_points: 0.1220
Epoch 86/100
2/2 [==============================] - 0s 27ms/step - train_loss_points: 0.1213 - val_test_loss_points: 0.1214
Epoch 87/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1214 - val_test_loss_points: 0.1201
Epoch 88/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1197 - val_test_loss_points: 0.1204
Epoch 89/100
2/2 [==============================] - 0s 21ms/step - train_loss_points: 0.1193 - val_test_loss_points: 0.1185
Epoch 90/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1193 - val_test_loss_points: 0.1185
Epoch 91/100
2/2 [==============================] - 0s 18ms/step - train_loss_points: 0.1175 - val_test_loss_points: 0.1177
Epoch 92/100
2/2 [==============================] - 0s 26ms/step - train_loss_points: 0.1170 - val_test_loss_points: 0.1162
Epoch 93/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1155 - val_test_loss_points: 0.1159
Epoch 94/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1151 - val_test_loss_points: 0.1146
Epoch 95/100
2/2 [==============================] - 0s 23ms/step - train_loss_points: 0.1144 - val_test_loss_points: 0.1142
Epoch 96/100
2/2 [==============================] - 0s 20ms/step - train_loss_points: 0.1132 - val_test_loss_points: 0.1134
Epoch 97/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1127 - val_test_loss_points: 0.1126
Epoch 98/100
2/2 [==============================] - 0s 22ms/step - train_loss_points: 0.1120 - val_test_loss_points: 0.1119
Epoch 99/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1112 - val_test_loss_points: 0.1113
Epoch 100/100
2/2 [==============================] - 0s 19ms/step - train_loss_points: 0.1106 - val_test_loss_points: 0.1107
Residual Domain model training time :: 16.355227697

ID=[]
Leaf=False
Subdomain lower=[0. 0.]
Subdomain upper=[1. 1.]
Subdomain split_dim=1
Subdomain split_value=0.5390629768371582
Regressions:
Subdomain offset=None

ID=['1']
Leaf=True
Subdomain lower=[0. 0.]
Subdomain upper=[1.        0.5390625]
Subdomain split_dim=-1
Subdomain split_value=nan
Regressions:
-1.4461549580543382 * x1 +$lb$4.045129278376367 * std::pow(x1, 2)
Sample value=0.4776937469631697
Subdomain offset=None

ID=['2']
Leaf=True
Subdomain lower=[0.        0.5390625]
Subdomain upper=[1. 1.]
Subdomain split_dim=-1
Subdomain split_value=nan
Regressions:
-5.763342371122453 * x1 +$lb$9.831191635894765 * std::pow(x1, 2)
Sample value=0.7252067590296403
Subdomain offset=None
idx = 0
idx = 1
Mean Squared Error (Training Data)::  0.037927555954870185
Root Mean Squared Error (Training Data)::  0.19474998319607165
idx = 0
idx = 1
Total testing time :: 0.22099836900000014
Mean Squared Error (Out of sample test)::  0.03875025141723599
Root Mean Squared Error (Out of sample test)::  0.19685083544967746

Process finished with exit code 0
